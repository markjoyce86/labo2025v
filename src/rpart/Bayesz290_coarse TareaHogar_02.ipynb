{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea para el Hogar 02"
      ],
      "metadata": {
        "id": "F3r8aa3pBigj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta Tarea para el Hogar 02 se entrega el final de la segunda clase\n",
        "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 03, ya que se analizarán los resultados"
      ],
      "metadata": {
        "id": "nBm4ktHUBmZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Ensembles de Modelos"
      ],
      "metadata": {
        "id": "TK-M04ElCESC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vea el siguiente video [BBC - The Code - The Wisdom of the Crowd](https://www.youtube.com/watch?v=iOucwX7Z1HU)    ( 5 min)\n"
      ],
      "metadata": {
        "id": "biPYxgobCOSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lea los siguientes artículos\n",
        "\n",
        "\n",
        "*   [The Wisdom of Crowds (Vox Populi) by Francis Galton](https://www.all-about-psychology.com/the-wisdom-of-crowds.html)  (10 min)\n",
        "*   [A Gentle Introduction to Ensemble Learning](https://machinelearningmastery.com/what-is-ensemble-learning/)  (10 min)\n",
        "\n"
      ],
      "metadata": {
        "id": "FBszBRyNCcjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "x7SebtV2lpHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  2.  Zero2Hero   primera parte\n",
        "Se han lanzado los primeros fascículos coleccionables llamados \"from Zero to Hero\" que muy detalladamente, paso a paso enseñan todo lo necesario de R para entender los scripts oficiales de la asignatura.\n",
        "Están en el repositorio oficial de la asignatura, carpeta  **src/zero2hero**"
      ],
      "metadata": {
        "id": "NQcY8u2MDSLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GcO0OSiIEAGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.  Grid Search"
      ],
      "metadata": {
        "id": "6MStcyn0EBdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busque en internet el precido significado de los hiperparámetros de la librería **rpart**  que está implementando el algoritmo **CART**  Classification and Regression Trees  propuesto en el año 1984 por Leo Brieman:\n",
        "\n",
        "*   cp\n",
        "*   maxdepth\n",
        "*   minsplit\n",
        "*   minbucket\n",
        "\n",
        "Entienda que valores es razonable tome cada hiperparámetro,  en particular profundice en el hiperparámetro  **cp**  y la posibilidad que tome valores negativos.  Es válido consultar a su amigo de *capacidades especiales*  ChatGPT\n"
      ],
      "metadata": {
        "id": "gM8RKXDgEIY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En las siguientes celdas a un notebook incompleto, un esqueleto de codigo brindado a modo de facilitarle la tarea de codeo y permitir que su valiosa cognición se concentre temas conceptuales de Ciencia de Datos\n",
        "\n",
        "Modifiquelo agregando loops para que recorra TODOS los hiperparámetros de rpart  < cp, maxdepth, minsplit, minbucket >, y luego póngalo a correr. Recuerde cambiar por SU semilla\n",
        "Tenga muy presente la granularidad que eligirá para cada hiperparámetro."
      ],
      "metadata": {
        "id": "_k7eT3HIFy9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "kmLygy1TYPfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Tipe -> Runtime type ->  **Python 3**"
      ],
      "metadata": {
        "id": "OikOm5K2YU3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ],
      "metadata": {
        "id": "4fmV5LyZdFyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ],
      "metadata": {
        "id": "ilEZ-bE2VybW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "ilaKtqWldeWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n",
        "\n"
      ],
      "metadata": {
        "id": "W8dQFI5QYCFa",
        "outputId": "20f8b8a0-1166-4927-c347-37615b428025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "limpio el ambiente de R"
      ],
      "metadata": {
        "id": "SE94XRhWsxkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ],
      "metadata": {
        "id": "oZG_4br6szlT",
        "outputId": "46d98f79-c360-41d5-83e2-9359e07ef41b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 657245</td><td>35.2</td><td>1454454</td><td>77.7</td><td>1326126</td><td>70.9</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1220272</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1975128</td><td>15.1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells |  657245 | 35.2 | 1454454 | 77.7 | 1326126 | 70.9 |\n| Vcells | 1220272 |  9.4 | 8388608 | 64.0 | 1975128 | 15.1 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells &  657245 & 35.2 & 1454454 & 77.7 & 1326126 & 70.9\\\\\n\tVcells & 1220272 &  9.4 & 8388608 & 64.0 & 1975128 & 15.1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  657245 35.2 1454454    77.7 1326126  70.9\n",
              "Vcells 1220272  9.4 8388608    64.0 1975128  15.1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "require(\"parallel\")\n",
        "if (!require(\"primes\")) install.packages(\"primes\")\n",
        "require(\"primes\")"
      ],
      "metadata": {
        "id": "JO-12d7YHkWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bd8271-b4e9-4de1-cfe7-470806aa2903"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: data.table\n",
            "\n",
            "Loading required package: rpart\n",
            "\n",
            "Loading required package: parallel\n",
            "\n",
            "Loading required package: primes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe poner SU semiila primigenia"
      ],
      "metadata": {
        "id": "0MclPEJ6Q8Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "# reemplazar por su primer semilla\n",
        "PARAM$semilla_primigenia <- 765179\n",
        "PARAM$qsemillas <- 10\n",
        "\n",
        "PARAM$training_pct <- 70L  # entre  1L y 99L\n",
        "\n",
        "# elegir SU dataset comentando/ descomentando\n",
        "PARAM$dataset_nom <- \"~/datasets/dataset_pequeno.csv\""
      ],
      "metadata": {
        "id": "Vt5fC6bWHu5r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# particionar agrega una columna llamada fold a un dataset\n",
        "#  que consiste en una particion estratificada segun agrupa\n",
        "# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)\n",
        "#   crea una particion 70, 30\n",
        "\n",
        "particionar <- function(data, division, agrupa = \"\", campo = \"fold\", start = 1, seed = NA) {\n",
        "  if (!is.na(seed)) set.seed(seed)\n",
        "\n",
        "  bloque <- unlist(mapply(function(x, y) {\n",
        "    rep(y, x)\n",
        "  }, division, seq(from = start, length.out = length(division))))\n",
        "\n",
        "  data[, (campo) := sample(rep(bloque, ceiling(.N / length(bloque))))[1:.N],\n",
        "    by = agrupa\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "Z1dchsrWH4MD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ArbolEstimarGanancia <- function(semilla, training_pct, param_basicos) {\n",
        "  # particiono estratificadamente el dataset\n",
        "  particionar(dataset,\n",
        "    division = c(training_pct, 100L -training_pct),\n",
        "    agrupa = \"clase_ternaria\",\n",
        "    seed = semilla # aqui se usa SU semilla\n",
        "  )\n",
        "\n",
        "  # genero el modelo\n",
        "  # predecir clase_ternaria a partir del resto\n",
        "  modelo <- rpart(\"clase_ternaria ~ .\",\n",
        "    data = dataset[fold == 1], # fold==1  es training,  el 70% de los datos\n",
        "    xval = 0,\n",
        "    control = param_basicos\n",
        "  ) # aqui van los parametros del arbol\n",
        "\n",
        "  # aplico el modelo a los datos de testing\n",
        "  prediccion <- predict(modelo, # el modelo que genere recien\n",
        "    dataset[fold == 2], # fold==2  es testing, el 30% de los datos\n",
        "    type = \"prob\"\n",
        "  ) # type= \"prob\"  es que devuelva la probabilidad\n",
        "\n",
        "  # prediccion es una matriz con TRES columnas,\n",
        "  #  llamadas \"BAJA+1\", \"BAJA+2\"  y \"CONTINUA\"\n",
        "  # cada columna es el vector de probabilidades\n",
        "\n",
        "\n",
        "  # calculo la ganancia en testing  qu es fold==2\n",
        "  ganancia_test <- dataset[\n",
        "    fold == 2,\n",
        "    sum(ifelse(prediccion[, \"BAJA+2\"] > 0.025,\n",
        "      ifelse(clase_ternaria == \"BAJA+2\", 117000, -3000),\n",
        "      0\n",
        "    ))\n",
        "  ]\n",
        "\n",
        "  # escalo la ganancia como si fuera todo el dataset\n",
        "  ganancia_test_normalizada <- ganancia_test / (( 100 - PARAM$training_pct ) / 100 )\n",
        "\n",
        "  return(\n",
        "    c( list(\"semilla\" = semilla),\n",
        "      param_basicos,\n",
        "      list( \"ganancia_test\" = ganancia_test_normalizada )\n",
        "     )\n",
        "  )\n",
        "}"
      ],
      "metadata": {
        "id": "xsHwS1CzIA70"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ArbolesMontecarlo <- function(semillas, param_basicos) {\n",
        "\n",
        "  # la funcion mcmapply  llama a la funcion ArbolEstimarGanancia\n",
        "  #  tantas veces como valores tenga el vector  PARAM$semillas\n",
        "  salida <- mcmapply(ArbolEstimarGanancia,\n",
        "    semillas, # paso el vector de semillas\n",
        "    MoreArgs = list(PARAM$training_pct, param_basicos), # aqui paso el segundo parametro\n",
        "    SIMPLIFY = FALSE,\n",
        "    mc.cores = detectCores()\n",
        "  )\n",
        "\n",
        "  return(salida)\n",
        "}"
      ],
      "metadata": {
        "id": "BvBVOuhqIEjD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "# por fabor cambiar numero de experimento si se cambia el loop principal\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- \"HT2900\"\n",
        "dir.create(experimento, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ],
      "metadata": {
        "id": "L-DOGHOjIG7G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")\n",
        "\n",
        "# trabajo solo con los datos con clase, es decir 202107\n",
        "dataset <- dataset[clase_ternaria != \"\"]"
      ],
      "metadata": {
        "id": "NM-mrLWcIPo6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero numeros primos\n",
        "primos <- generate_primes(min = 100000, max = 1000000)\n",
        "set.seed(PARAM$semilla_primigenia) # inicializo\n",
        "# me quedo con PARAM$qsemillas   semillas\n",
        "PARAM$semillas <- sample(primos, PARAM$qsemillas )"
      ],
      "metadata": {
        "id": "tSlY0EcgIWdi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero la data.table donde van los resultados detallados del Grid Search\n",
        "# un registro para cada combinacion de < semilla, parametros >\n",
        "\n",
        "if(file.exists(\"autogridsearch_detalle.txt\")){\n",
        "  tb_grid_search_detalle <- fread(\"autogridsearch_detalle.txt\")\n",
        "}else{\n",
        "  tb_grid_search_detalle <- data.table(\n",
        "    semilla = integer(),\n",
        "    cp = numeric(),\n",
        "    maxdepth = integer(),\n",
        "   minsplit = integer(),\n",
        "    minbucket = integer(),\n",
        "    ganancia_test = numeric()\n",
        "  )\n",
        "}\n",
        "\n",
        "nrow( tb_grid_search_detalle )"
      ],
      "metadata": {
        "id": "xxCAwIKyIaTl",
        "outputId": "11ce774c-0eff-4bed-d3da-3e6b2f4bbc11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0"
            ],
            "text/markdown": "0",
            "text/latex": "0",
            "text/plain": [
              "[1] 0"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data.table threads (0 = auto use all)\n",
        "data.table::setDTthreads(0)\n",
        "data.table::getDTthreads()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1kEF1wvkozIh",
        "outputId": "d6847788-fe47-4ef3-a8c4-194cf5fc8017"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "8"
            ],
            "text/markdown": "8",
            "text/latex": "8",
            "text/plain": [
              "[1] 8"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la parte del código que usted debe expandir a TODOS los hiperparámetros de rpart,\n",
        "<br>ya que actualmente apenas recorre  maxdepth y  minsplit  dejando fijos  cp=-0.5  y minbucket=5"
      ],
      "metadata": {
        "id": "eAuGBNL8IkOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(httr)\n",
        "\n",
        "# choose any topic name (use something unique)\n",
        "topic <- \"mark_labo2025\"\n",
        "\n",
        "# message to send\n",
        "msg <- \"✅ Grid Search finished successfully!\"\n",
        "\n",
        "httr::POST(\n",
        "  url = paste0(\"https://ntfy.sh/\", topic),\n",
        "  body = msg,\n",
        "  encode = \"raw\"\n",
        ")"
      ],
      "metadata": {
        "id": "za4kOLXTI5OK",
        "outputId": "bcf078fb-e4c1-4d09-b210-450fa3bd1f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Response [https://ntfy.sh/mark_labo2025]\n",
              "  Date: 2025-10-14 16:10\n",
              "  Status: 200\n",
              "  Content-Type: application/json\n",
              "  Size: 154 B\n",
              "{\"id\":\"RaLiKqnokWJV\",\"time\":1760458251,\"expires\":1760501451,\"event\":\"message\"..."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fwrite( tb_grid_search_detalle,\n",
        "   file = \"autogridsearch_detalle.txt\",\n",
        "   sep = \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "WZaSqYBxiDFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "bf1375f0-2bc4-44b5-e079-e182940c4e66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error: object 'tb_grid_search_detalle' not found\n",
          "traceback": [
            "Error: object 'tb_grid_search_detalle' not found\nTraceback:\n",
            "1. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"object 'tb_grid_search_detalle' not found\", base::quote(eval(expr, \n .     envir)))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cantidad de registros de la tabla\n",
        "nrow(tb_grid_search_detalle)"
      ],
      "metadata": {
        "id": "STp0duM-RYVJ",
        "outputId": "0b06eca2-e6c7-4adf-bda1-5fc5e1bbdab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0"
            ],
            "text/markdown": "0",
            "text/latex": "0",
            "text/plain": [
              "[1] 0"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# muestro la tabla\n",
        "tb_grid_search_detalle"
      ],
      "metadata": {
        "id": "k7fhk_H0iNez",
        "outputId": "a6850938-4bc8-4386-8c46-db68d3bf93cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.table: 0 × 6</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>semilla</th><th scope=col>cp</th><th scope=col>maxdepth</th><th scope=col>minsplit</th><th scope=col>minbucket</th><th scope=col>ganancia_test</th></tr>\n",
              "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.table: 0 × 6\n\n| semilla &lt;int&gt; | cp &lt;dbl&gt; | maxdepth &lt;int&gt; | minsplit &lt;int&gt; | minbucket &lt;int&gt; | ganancia_test &lt;dbl&gt; |\n|---|---|---|---|---|---|\n\n",
            "text/latex": "A data.table: 0 × 6\n\\begin{tabular}{llllll}\n semilla & cp & maxdepth & minsplit & minbucket & ganancia\\_test\\\\\n <int> & <dbl> & <int> & <int> & <int> & <dbl>\\\\\n\\hline\n\\end{tabular}\n",
            "text/plain": [
              "     semilla cp maxdepth minsplit minbucket ganancia_test"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "126c55f2"
      },
      "source": [
        "## Track the best hyperparameters and gain\n",
        "\n",
        "### Subtask:\n",
        "Modify the code to keep track of the best hyperparameters found during the optimization process and their corresponding gain."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# genero y grabo el resumen\n",
        "tb_grid_search <- tb_grid_search_detalle[,\n",
        "  list( \"ganancia_mean\" = mean(ganancia_test),\n",
        "    \"qty\" = .N ),\n",
        "  list( cp, maxdepth, minsplit, minbucket )\n",
        "]\n"
      ],
      "metadata": {
        "id": "DjCxtx8bIsgl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ordeno descendente por ganancia\n",
        "setorder( tb_grid_search, -ganancia_mean )"
      ],
      "metadata": {
        "id": "LU29UhL1Ivg5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veo los 10 mejores hiperparámetros\n",
        "tb_grid_search[1:10]"
      ],
      "metadata": {
        "id": "g-EjGY7aIyWL",
        "outputId": "706c714a-6a63-4298-cfb9-f55bb9282a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.table: 10 × 6</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>cp</th><th scope=col>maxdepth</th><th scope=col>minsplit</th><th scope=col>minbucket</th><th scope=col>ganancia_mean</th><th scope=col>qty</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "\t<tr><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.table: 10 × 6\n\n| cp &lt;dbl&gt; | maxdepth &lt;int&gt; | minsplit &lt;int&gt; | minbucket &lt;int&gt; | ganancia_mean &lt;dbl&gt; | qty &lt;int&gt; |\n|---|---|---|---|---|---|\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n| NA | NA | NA | NA | NA | NA |\n\n",
            "text/latex": "A data.table: 10 × 6\n\\begin{tabular}{llllll}\n cp & maxdepth & minsplit & minbucket & ganancia\\_mean & qty\\\\\n <dbl> & <int> & <int> & <int> & <dbl> & <int>\\\\\n\\hline\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\t NA & NA & NA & NA & NA & NA\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   cp maxdepth minsplit minbucket ganancia_mean qty\n",
              "1  NA NA       NA       NA        NA            NA \n",
              "2  NA NA       NA       NA        NA            NA \n",
              "3  NA NA       NA       NA        NA            NA \n",
              "4  NA NA       NA       NA        NA            NA \n",
              "5  NA NA       NA       NA        NA            NA \n",
              "6  NA NA       NA       NA        NA            NA \n",
              "7  NA NA       NA       NA        NA            NA \n",
              "8  NA NA       NA       NA        NA            NA \n",
              "9  NA NA       NA       NA        NA            NA \n",
              "10 NA NA       NA       NA        NA            NA "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# genero un id a la tabla\n",
        "tb_grid_search[, id := .I ]\n",
        "\n",
        "fwrite( tb_grid_search,\n",
        "  file = \"autogridsearch.txt\",\n",
        "  sep = \"\\t\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "K3S-I2PTI5ZE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d107a9b"
      },
      "source": [
        "Now that you have the top 100 parameter combinations, you can analyze the ranges of `cp`, `maxdepth`, `minsplit`, and `minbucket` that appear most frequently among these high-performing combinations. This analysis will help you determine the best ranges for manual reproduction or further investigation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.  Análisis de resultados de Grid Search"
      ],
      "metadata": {
        "id": "1rYHk1YkI_9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La salida de la corrida anterior queda en ~/buckets/b1/exp/HT2900  que corresponde a su Google Drive\n",
        "<br>HT significa Hyperparameter Tuning\n",
        "<br>El Grid Search es un método de fuerza bruta de un altísimo costo computacional.\n",
        "<br>Queremos ver si es posible crear un algoritmo de optimización de hiperparámetros que se ahorre recorrer ciertas porciones muy malas del espacio de búsqueda. Algo del estilo “cada vez que pruebo una combinación de hiperparámetros donde  cp > 1 , la ganancia es muy mala, con lo cual ni vale la pena perder el tiempo explorando en esa region”\n"
      ],
      "metadata": {
        "id": "ZTJgPhMWJHTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>Levante el archivo de salida gridsearch.txt  a una planilla tipo Excel y analícelo detenidamente\n",
        "<br>Ordene por ganancia_mean descendente\n",
        "<br>\n",
        "<br>El de mayor ganancia_mean  decimos que es el primero del ranking\n",
        "En Zulip, correspondiente channel  #Tarea Hogar 02 , topic Analisis Grid Search   intente contestar estas preguntas:\n",
        "\n",
        "* ¿Qué combinaciones de hiperparámetros poseen una ganancia muy buena?\n",
        "* ¿Hay algun hiperparámetro que para cierto valor siempre genera una ganancia muy mala, a independientemente de lo que valgan los otros hiperparámetros ?\n",
        "* ¿Que combinaciones de hiperparámetros es pésima y hubiera sido bueno ahorrarse esas corridas ?\n",
        "\n",
        "( tiempo estimado 30 minutos, dificultad media )"
      ],
      "metadata": {
        "id": "IaVgMu4tPwyB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23c20e40"
      },
      "source": [
        "## Track the best hyperparameters and gain\n",
        "\n",
        "### Subtask:\n",
        "Modify the code to keep track of the best hyperparameters found during the optimization process and their corresponding gain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40b6bdcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ba6c91-abe1-495e-a6d6-b7af7e5ca618"
      },
      "source": [
        "# Install and load the rBayesianOptimization package if not already available\n",
        "if (!require(\"rBayesianOptimization\")) install.packages(\"rBayesianOptimization\")\n",
        "require(\"rBayesianOptimization\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: rBayesianOptimization\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘rBayesianOptimization’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘iterators’, ‘lhs’, ‘foreach’, ‘GPfit’\n",
            "\n",
            "\n",
            "Loading required package: rBayesianOptimization\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e5078ec"
      },
      "source": [
        "# Define the objective function to maximize\n",
        "EstimarGananciaHiperparametros <- function(cp, maxdepth, minsplit, minbucket) {\n",
        "  # Ensure integer hyperparameters are treated as integers\n",
        "  maxdepth <- as.integer(maxdepth)\n",
        "  minsplit <- as.integer(minsplit)\n",
        "  minbucket <- as.integer(minbucket)\n",
        "\n",
        "  # Set the hyperparameters for rpart control\n",
        "  param_basicos <- list(\n",
        "    cp = cp,\n",
        "    maxdepth = maxdepth,\n",
        "    minsplit = minsplit,\n",
        "    minbucket = minbucket\n",
        "  )\n",
        "\n",
        "  # Run Monte Carlo simulation with the given hyperparameters\n",
        "  ganancias <- ArbolesMontecarlo(PARAM$semillas, param_basicos)\n",
        "\n",
        "  # Calculate the mean gain\n",
        "  ganancia_promedio <- mean(sapply(ganancias, \"[[\", \"ganancia_test\"))\n",
        "\n",
        "  # Return the mean gain (the objective function value)\n",
        "  return(list(Score = ganancia_promedio, Pred = 0)) # BayesianOptimization expects a list with Score and Pred\n",
        "}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aecd6ac"
      },
      "source": [
        "# Define the bounds for each hyperparameter, including negative values for cp\n",
        "bounds <- list(\n",
        "  cp = c(-1, 0.1), # cp can be between -0.01 and 0.01\n",
        "  maxdepth = c(3L, 15L), # maxdepth can be between 3 and 15 (integer)\n",
        "  minsplit = c(2L, 3000L), # minsplit can be between 2 and 2000 (integer)\n",
        "  minbucket = c(1L, 1000L) # minbucket can be between 1 and 1000 (integer)\n",
        ")\n",
        "\n",
        "# Perform Bayesian Optimization\n",
        "set.seed(PARAM$semilla_primigenia) # Set seed for reproducibility\n",
        "bayes_opt_result <- BayesianOptimization(\n",
        "  FUN = EstimarGananciaHiperparametros, # The objective function to maximize\n",
        "  bounds = bounds, # The hyperparameter bounds\n",
        "  init_points = 20, # Number of initial random points\n",
        "  n_iter = 80, # Number of iterations for optimization\n",
        "  acq = \"ei\", # Acquisition function (Upper Confidence Bound)\n",
        "  #kappa = 2.576, # Kappa value for UCB (exploratory vs exploitative trade-off)\n",
        "  eps = 0.04, # Epsilon for epsilon-greedy acquisition function\n",
        "  verbose = TRUE # Print optimization progress\n",
        ")\n",
        "\n",
        "# Print the best parameters found\n",
        "print(bayes_opt_result$Best_Par)\n",
        "print(bayes_opt_result$Best_Value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98f24158"
      },
      "source": [
        "# Get the results from the Bayesian optimization\n",
        "optimization_results <- bayes_opt_result$History\n",
        "\n",
        "# Display column names to identify the gain column\n",
        "print(colnames(optimization_results))\n",
        "\n",
        "# Convert the results to a data.table\n",
        "tb_optimization_results <- as.data.table(optimization_results)\n",
        "\n",
        "# Order the results by the gain (Value) in descending order\n",
        "setorder(tb_optimization_results, -Value)\n",
        "\n",
        "# Display the top 100 parameter combinations and their gain\n",
        "print(tb_optimization_results[1:100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero un id a la tabla\n",
        "tb_optimization_results[, id := .I ]\n",
        "\n",
        "fwrite( tb_optimization_results,\n",
        "  file = \"BayesGridSearch.txt\",\n",
        "  sep = \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "9OtcPda0RFIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b38e95a2"
      },
      "source": [
        "### change to Python\n",
        "## Store the results\n",
        "\n",
        "### Subtask:\n",
        "Save the results of the optimization process, including the best hyperparameters and the maximum gain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68324df8"
      },
      "source": [
        "# This code should be run in a Python cell with a Python 3 runtime.\n",
        "\n",
        "def generate_nested_loops_from_top_params(optimization_results_dt, num_top_combinations=100):\n",
        "  \"\"\"\n",
        "  Analyzes the top parameter combinations from optimization results and\n",
        "  generates a nested loop structure based on the unique values.\n",
        "\n",
        "  Args:\n",
        "    optimization_results_dt: A data.table containing the optimization history,\n",
        "                             sorted by gain in descending order.\n",
        "    num_top_combinations: The number of top combinations to consider.\n",
        "  \"\"\"\n",
        "  top_params = optimization_results_dt[1:min(num_top_combinations, nrow(optimization_results_dt))]\n",
        "\n",
        "  unique_cp = unique(top_params$cp)\n",
        "  unique_maxdepth = unique(top_params$maxdepth)\n",
        "  unique_minsplit = unique(top_params$minsplit)\n",
        "  unique_minbucket = unique(top_params$minbucket)\n",
        "\n",
        "  print(\"Generated Nested Loops (based on unique values from top {} combinations):\".format(num_top_combinations))\n",
        "  print(\"for (cp in c({})) {{\".format(\", \".join(map(str, unique_cp))))\n",
        "  print(\"  for (maxdepth in c({})) {{\".format(\", \".join(map(str, unique_maxdepth))))\n",
        "  print(\"    for (minsplit in c({})) {{\".format(\", \".join(map(str, unique_minsplit))))\n",
        "  print(\"      for (minbucket in c({})) {{\".format(\", \".join(map(str, unique_minbucket))))\n",
        "  print(\"        # Your code to evaluate this parameter combination goes here\")\n",
        "  print(\"      }\")\n",
        "  print(\"    }\")\n",
        "  print(\"  }\")\n",
        "  print(\"}\")\n",
        "\n",
        "# Example usage with your optimization results data.table\n",
        "# Assuming tb_optimization_results is already sorted by Value descending\n",
        "generate_nested_loops_from_top_params(tb_optimization_results, num_top_combinations=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b530b096"
      },
      "source": [
        "# Task\n",
        "Improve the Bayesian Optimization process to find better hyperparameters for the decision tree model, aiming for higher average gains, by increasing the number of iterations, refining hyperparameter bounds, experimenting with different acquisition functions, increasing the number of initial points, considering cross-validation, increasing the number of seeds for Monte Carlo simulation, and ensuring effective parallel processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9a26a72"
      },
      "source": [
        "## Analyze current results\n",
        "\n",
        "### Subtask:\n",
        "Review the current Bayesian Optimization results (`bayes_opt_result`) to understand the range of hyperparameters explored and the resulting gains. This can help identify if the optimization is converging or if it's still exploring promising regions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ae611a9"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the best parameters and value from the Bayesian optimization results and show the history of the optimization to understand the explored hyperparameter space and resulting gains.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23a4b377",
        "outputId": "e028155b-4443-40c2-fe60-92c17341f753"
      },
      "source": [
        "print(\"Best Parameters Found:\")\n",
        "print(bayes_opt_result$Best_Par)\n",
        "print(\"\\nBest Value (Mean Gain):\")\n",
        "print(bayes_opt_result$Best_Value)\n",
        "\n",
        "print(\"\\nOptimization History (showing the first 10 rows):\")\n",
        "print(tb_optimization_results[1:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Best Parameters Found:\"\n",
            "          cp     maxdepth     minsplit    minbucket \n",
            "  -0.4187299    6.0000000 1582.0000000  283.0000000 \n",
            "[1] \"\\nBest Value (Mean Gain):\"\n",
            "[1] 48182000\n",
            "[1] \"\\nOptimization History (showing the first 10 rows):\"\n",
            "    Round         cp maxdepth minsplit minbucket    Value    id\n",
            "    <int>      <num>    <num>    <num>     <num>    <num> <int>\n",
            " 1:    37 -0.4187299        6     1582       283 48182000     1\n",
            " 2:     2 -0.5410928        7     1973       283 47876000     2\n",
            " 3:    31 -0.4455829        8      717       491 47824000     3\n",
            " 4:     8 -0.8411148        6     1995       491 47714000     4\n",
            " 5:     4 -0.2819756        8      309       453 47702000     5\n",
            " 6:    22 -0.7660754       14        2      1000 47376000     6\n",
            " 7:    24 -0.4798067       12     1851      1000 47376000     7\n",
            " 8:    25 -0.7664998       14     1175      1000 47376000     8\n",
            " 9:     9 -0.8361868        9     1894        47 46894000     9\n",
            "10:     7 -0.6241211        9     2001       987 46764000    10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa232efc"
      },
      "source": [
        "**Reasoning**:\n",
        "Analyze the range of explored hyperparameters and their relationship with the gain from the optimization history to understand the effectiveness of the current optimization process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8221dd1",
        "outputId": "e29c260b-88b6-4960-f001-f38f9b5766f8"
      },
      "source": [
        "# Analyze the distribution of hyperparameters in the top performing combinations\n",
        "print(\"\\nSummary statistics for hyperparameters in the top 100 combinations:\")\n",
        "print(summary(tb_optimization_results[1:100]))\n",
        "\n",
        "# Look for trends in hyperparameter values as gain increases\n",
        "# This is a basic visual inspection, more detailed analysis might involve plotting\n",
        "print(\"\\nHyperparameter values and gain for the top 20 combinations:\")\n",
        "print(tb_optimization_results[1:100, c(\"cp\", \"maxdepth\", \"minsplit\", \"minbucket\", \"Value\")])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"\\nSummary statistics for hyperparameters in the top 100 combinations:\"\n",
            "     Round             cp              maxdepth         minsplit     \n",
            " Min.   : 1.00   Min.   :-1.00000   Min.   : 3.000   Min.   :   2.0  \n",
            " 1st Qu.:10.75   1st Qu.:-0.83695   1st Qu.: 3.000   1st Qu.: 654.2  \n",
            " Median :20.50   Median :-0.53303   Median : 8.000   Median :1714.0  \n",
            " Mean   :20.50   Mean   :-0.52800   Mean   : 8.425   Mean   :1508.8  \n",
            " 3rd Qu.:30.25   3rd Qu.:-0.27831   3rd Qu.:13.250   3rd Qu.:2062.8  \n",
            " Max.   :40.00   Max.   : 0.09065   Max.   :15.000   Max.   :3000.0  \n",
            " NA's   :60      NA's   :60         NA's   :60       NA's   :60      \n",
            "   minbucket          Value                id       \n",
            " Min.   :   1.0   Min.   :       0   Min.   : 1.00  \n",
            " 1st Qu.: 250.0   1st Qu.:45104000   1st Qu.:10.75  \n",
            " Median : 836.5   Median :45838000   Median :20.50  \n",
            " Mean   : 612.0   Mean   :41065500   Mean   :20.50  \n",
            " 3rd Qu.:1000.0   3rd Qu.:46764000   3rd Qu.:30.25  \n",
            " Max.   :1000.0   Max.   :48182000   Max.   :40.00  \n",
            " NA's   :60       NA's   :60         NA's   :60     \n",
            "[1] \"\\nHyperparameter values and gain for the top 20 combinations:\"\n",
            "            cp maxdepth minsplit minbucket    Value\n",
            "         <num>    <num>    <num>     <num>    <num>\n",
            " 1: -0.4187299        6     1582       283 48182000\n",
            " 2: -0.5410928        7     1973       283 47876000\n",
            " 3: -0.4455829        8      717       491 47824000\n",
            " 4: -0.8411148        6     1995       491 47714000\n",
            " 5: -0.2819756        8      309       453 47702000\n",
            " 6: -0.7660754       14        2      1000 47376000\n",
            " 7: -0.4798067       12     1851      1000 47376000\n",
            " 8: -0.7664998       14     1175      1000 47376000\n",
            " 9: -0.8361868        9     1894        47 46894000\n",
            "10: -0.6241211        9     2001       987 46764000\n",
            "11: -0.3560067       11      955       987 46764000\n",
            "12: -0.1419232        9     1919       824 46316000\n",
            "13: -0.4351745        5     3000      1000 46258000\n",
            "14: -0.1805083       15     1979         1 46186000\n",
            "15: -0.3676655       14     1362         1 45956000\n",
            "16: -0.6057289       13     2002       958 45884000\n",
            "17: -0.3610291        3       88      1000 45838000\n",
            "18: -1.0000000        3     1685      1000 45838000\n",
            "19: -1.0000000        3        2      1000 45838000\n",
            "20: -0.8392306        3        2      1000 45838000\n",
            "            cp maxdepth minsplit minbucket    Value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a79cb5c1"
      },
      "source": [
        "## Increase the number of iterations\n",
        "\n",
        "### Subtask:\n",
        "Increase the number of iterations (`n_iter`) in the `BayesianOptimization` function to allow for a more extensive exploration of the hyperparameter space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59a3e025"
      },
      "source": [
        "**Reasoning**:\n",
        "Increase the number of iterations in the BayesianOptimization function to explore the hyperparameter space more extensively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e63d32de",
        "outputId": "141453d9-4707-4bcf-f894-59458cb5c9ef"
      },
      "source": [
        "# Define the objective function to maximize\n",
        "EstimarGananciaHiperparametros <- function(cp, maxdepth, minsplit, minbucket) {\n",
        "  # Ensure integer hyperparameters are treated as integers\n",
        "  maxdepth <- as.integer(maxdepth)\n",
        "  minsplit <- as.integer(minsplit)\n",
        "  minbucket <- as.integer(minbucket)\n",
        "\n",
        "  # Set the hyperparameters for rpart control\n",
        "  param_basicos <- list(\n",
        "    cp = cp,\n",
        "    maxdepth = maxdepth,\n",
        "    minsplit = minsplit,\n",
        "    minbucket = minbucket\n",
        "  )\n",
        "\n",
        "  # Run Monte Carlo simulation with the given hyperparameters\n",
        "  ganancias <- ArbolesMontecarlo(PARAM$semillas, param_basicos)\n",
        "\n",
        "  # Calculate the mean gain\n",
        "  ganancia_promedio <- mean(sapply(ganancias, \"[[\", \"ganancia_test\"))\n",
        "\n",
        "  # Return the mean gain (the objective function value)\n",
        "  return(list(Score = ganancia_promedio, Pred = 0)) # BayesianOptimization expects a list with Score and Pred\n",
        "}\n",
        "\n",
        "\n",
        "# Define the bounds for each hyperparameter, including negative values for cp\n",
        "bounds <- list(\n",
        "  cp = c(-1, 0.1), # cp can be between -0.01 and 0.01\n",
        "  maxdepth = c(3L, 15L), # maxdepth can be between 3 and 15 (integer)\n",
        "  minsplit = c(2L, 3000L), # minsplit can be between 2 and 2000 (integer)\n",
        "  minbucket = c(1L, 1000L) # minbucket can be between 1 and 1000 (integer)\n",
        ")\n",
        "\n",
        "# Perform Bayesian Optimization\n",
        "set.seed(PARAM$semilla_primigenia) # Set seed for reproducibility\n",
        "bayes_opt_result <- BayesianOptimization(\n",
        "  FUN = EstimarGananciaHiperparametros, # The objective function to maximize\n",
        "  bounds = bounds, # The hyperparameter bounds\n",
        "  init_points = 20L, # Number of initial random points\n",
        "  n_iter = 80, # Number of iterations for optimization, increased from 30 to 90\n",
        "  acq = \"ei\", # Acquisition function (Upper Confidence Bound)\n",
        "  #kappa = 2.576, # Kappa value for UCB (exploratory vs exploitative trade-off)\n",
        "  eps = 0.01, # Epsilon for epsilon-greedy acquisition function\n",
        "  verbose = TRUE # Print optimization progress\n",
        ")\n",
        "\n",
        "# Print the best parameters found\n",
        "print(bayes_opt_result$Best_Par)\n",
        "print(bayes_opt_result$Best_Value)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed = 88.551\tRound = 1\tcp = -0.9250954\tmaxdepth = 6.0000\tminsplit = 439.0000\tminbucket = 382.0000\tValue = 47872000.0000 \n",
            "elapsed = 138.748\tRound = 2\tcp = -0.5410928\tmaxdepth = 11.0000\tminsplit = 982.0000\tminbucket = 895.0000\tValue = 45030000.0000 \n",
            "elapsed = 156.774\tRound = 3\tcp = -0.872166\tmaxdepth = 13.0000\tminsplit = 2261.0000\tminbucket = 230.0000\tValue = 44924000.0000 \n",
            "elapsed = 57.12\tRound = 4\tcp = -0.2819756\tmaxdepth = 4.0000\tminsplit = 2747.0000\tminbucket = 372.0000\tValue = 44738000.0000 \n",
            "elapsed = 166.094\tRound = 5\tcp = -0.6800285\tmaxdepth = 12.0000\tminsplit = 826.0000\tminbucket = 128.0000\tValue = 45619000.0000 \n",
            "elapsed = 9.459\tRound = 6\tcp = 0.04091623\tmaxdepth = 7.0000\tminsplit = 394.0000\tminbucket = 563.0000\tValue = 0.0000 \n",
            "elapsed = 145.466\tRound = 7\tcp = -0.6241211\tmaxdepth = 11.0000\tminsplit = 156.0000\tminbucket = 697.0000\tValue = 45794000.0000 \n",
            "elapsed = 143.083\tRound = 8\tcp = -0.8411148\tmaxdepth = 11.0000\tminsplit = 794.0000\tminbucket = 826.0000\tValue = 45517000.0000 \n",
            "elapsed = 149.499\tRound = 9\tcp = -0.8361868\tmaxdepth = 11.0000\tminsplit = 1574.0000\tminbucket = 153.0000\tValue = 46124000.0000 \n",
            "elapsed = 143.456\tRound = 10\tcp = -0.2595282\tmaxdepth = 10.0000\tminsplit = 827.0000\tminbucket = 492.0000\tValue = 46488000.0000 \n",
            "elapsed = 169.656\tRound = 11\tcp = -0.08610012\tmaxdepth = 14.0000\tminsplit = 1731.0000\tminbucket = 265.0000\tValue = 45896000.0000 \n",
            "elapsed = 88.243\tRound = 12\tcp = -0.6367185\tmaxdepth = 6.0000\tminsplit = 1149.0000\tminbucket = 994.0000\tValue = 46271000.0000 \n",
            "elapsed = 96.896\tRound = 13\tcp = -0.01294212\tmaxdepth = 7.0000\tminsplit = 2588.0000\tminbucket = 963.0000\tValue = 44710000.0000 \n",
            "elapsed = 112.989\tRound = 14\tcp = -0.5521567\tmaxdepth = 8.0000\tminsplit = 819.0000\tminbucket = 974.0000\tValue = 45303000.0000 \n",
            "elapsed = 122.455\tRound = 15\tcp = -0.9568785\tmaxdepth = 9.0000\tminsplit = 1725.0000\tminbucket = 709.0000\tValue = 45928000.0000 \n",
            "elapsed = 138.79\tRound = 16\tcp = -0.0006459069\tmaxdepth = 11.0000\tminsplit = 1069.0000\tminbucket = 966.0000\tValue = 45526000.0000 \n",
            "elapsed = 150.708\tRound = 17\tcp = -0.4092663\tmaxdepth = 15.0000\tminsplit = 2268.0000\tminbucket = 644.0000\tValue = 44647000.0000 \n",
            "elapsed = 123.312\tRound = 18\tcp = -0.7195061\tmaxdepth = 9.0000\tminsplit = 898.0000\tminbucket = 829.0000\tValue = 45621000.0000 \n",
            "elapsed = 57.797\tRound = 19\tcp = -0.4555093\tmaxdepth = 4.0000\tminsplit = 1435.0000\tminbucket = 746.0000\tValue = 45820000.0000 \n",
            "elapsed = 185.389\tRound = 20\tcp = -0.5271565\tmaxdepth = 14.0000\tminsplit = 556.0000\tminbucket = 220.0000\tValue = 45339000.0000 \n",
            "elapsed = 154.355\tRound = 21\tcp = -0.4304234\tmaxdepth = 11.0000\tminsplit = 254.0000\tminbucket = 444.0000\tValue = 46811000.0000 \n",
            "elapsed = 152.537\tRound = 22\tcp = -0.9641772\tmaxdepth = 14.0000\tminsplit = 2736.0000\tminbucket = 403.0000\tValue = 44691000.0000 \n",
            "elapsed = 190.517\tRound = 23\tcp = -0.9981078\tmaxdepth = 15.0000\tminsplit = 2980.0000\tminbucket = 11.0000\tValue = 43513000.0000 \n",
            "elapsed = 73.707\tRound = 24\tcp = -0.4328164\tmaxdepth = 5.0000\tminsplit = 385.0000\tminbucket = 473.0000\tValue = 47958000.0000 \n",
            "elapsed = 6.824\tRound = 25\tcp = 0.1000\tmaxdepth = 3.0000\tminsplit = 1516.0000\tminbucket = 387.0000\tValue = 0.0000 \n",
            "elapsed = 228.625\tRound = 26\tcp = -0.09820537\tmaxdepth = 15.0000\tminsplit = 2.0000\tminbucket = 1.0000\tValue = 31207000.0000 \n",
            "elapsed = 122.421\tRound = 27\tcp = -0.04525205\tmaxdepth = 10.0000\tminsplit = 3000.0000\tminbucket = 1000.0000\tValue = 44218000.0000 \n",
            "elapsed = 42.558\tRound = 28\tcp = -0.8497442\tmaxdepth = 3.0000\tminsplit = 2.0000\tminbucket = 531.0000\tValue = 45280000.0000 \n",
            "elapsed = 6.78\tRound = 29\tcp = 0.1000\tmaxdepth = 3.0000\tminsplit = 3000.0000\tminbucket = 1000.0000\tValue = 0.0000 \n",
            "elapsed = 145.067\tRound = 30\tcp = -0.06937206\tmaxdepth = 10.0000\tminsplit = 220.0000\tminbucket = 296.0000\tValue = 45435000.0000 \n",
            "elapsed = 41.889\tRound = 31\tcp = -0.7798673\tmaxdepth = 3.0000\tminsplit = 3000.0000\tminbucket = 113.0000\tValue = 44297000.0000 \n",
            "elapsed = 138.207\tRound = 32\tcp = -0.07454933\tmaxdepth = 13.0000\tminsplit = 3000.0000\tminbucket = 851.0000\tValue = 44176000.0000 \n",
            "elapsed = 164.229\tRound = 33\tcp = -0.02992187\tmaxdepth = 14.0000\tminsplit = 463.0000\tminbucket = 600.0000\tValue = 46202000.0000 \n",
            "elapsed = 150.213\tRound = 34\tcp = -0.02674666\tmaxdepth = 15.0000\tminsplit = 2.0000\tminbucket = 1000.0000\tValue = 46149000.0000 \n",
            "elapsed = 145.027\tRound = 35\tcp = -0.3833524\tmaxdepth = 11.0000\tminsplit = 2616.0000\tminbucket = 24.0000\tValue = 44323000.0000 \n",
            "elapsed = 153.855\tRound = 36\tcp = -0.07433711\tmaxdepth = 15.0000\tminsplit = 2442.0000\tminbucket = 509.0000\tValue = 44608000.0000 \n",
            "elapsed = 99.741\tRound = 37\tcp = -0.8064353\tmaxdepth = 7.0000\tminsplit = 2.0000\tminbucket = 828.0000\tValue = 45377000.0000 \n",
            "elapsed = 126.004\tRound = 38\tcp = -0.7482256\tmaxdepth = 9.0000\tminsplit = 68.0000\tminbucket = 711.0000\tValue = 45922000.0000 \n",
            "elapsed = 56.693\tRound = 39\tcp = -0.4421993\tmaxdepth = 4.0000\tminsplit = 2819.0000\tminbucket = 499.0000\tValue = 44395000.0000 \n",
            "elapsed = 73.83\tRound = 40\tcp = -0.4883121\tmaxdepth = 5.0000\tminsplit = 246.0000\tminbucket = 215.0000\tValue = 47540000.0000 \n",
            "elapsed = 42.565\tRound = 41\tcp = -0.07565885\tmaxdepth = 3.0000\tminsplit = 1745.0000\tminbucket = 211.0000\tValue = 45296000.0000 \n",
            "elapsed = 161.546\tRound = 42\tcp = -0.4461724\tmaxdepth = 14.0000\tminsplit = 2.0000\tminbucket = 637.0000\tValue = 46067000.0000 \n",
            "elapsed = 119.929\tRound = 43\tcp = -0.2262096\tmaxdepth = 9.0000\tminsplit = 2868.0000\tminbucket = 11.0000\tValue = 45346000.0000 \n",
            "elapsed = 151.544\tRound = 44\tcp = -0.5882473\tmaxdepth = 13.0000\tminsplit = 2978.0000\tminbucket = 309.0000\tValue = 44515000.0000 \n",
            "elapsed = 72.511\tRound = 45\tcp = -0.1901628\tmaxdepth = 5.0000\tminsplit = 395.0000\tminbucket = 999.0000\tValue = 46031000.0000 \n",
            "elapsed = 158.435\tRound = 46\tcp = -0.3310417\tmaxdepth = 14.0000\tminsplit = 1198.0000\tminbucket = 570.0000\tValue = 46699000.0000 \n",
            "elapsed = 100.718\tRound = 47\tcp = -0.3525582\tmaxdepth = 7.0000\tminsplit = 370.0000\tminbucket = 731.0000\tValue = 45840000.0000 \n",
            "elapsed = 42.281\tRound = 48\tcp = -0.9013827\tmaxdepth = 3.0000\tminsplit = 2.0000\tminbucket = 722.0000\tValue = 46066000.0000 \n",
            "elapsed = 41.477\tRound = 49\tcp = -0.07246631\tmaxdepth = 3.0000\tminsplit = 1050.0000\tminbucket = 1000.0000\tValue = 45543000.0000 \n",
            "elapsed = 82.334\tRound = 50\tcp = -0.1663373\tmaxdepth = 6.0000\tminsplit = 2805.0000\tminbucket = 923.0000\tValue = 44706000.0000 \n",
            "elapsed = 135.518\tRound = 51\tcp = -0.1035059\tmaxdepth = 14.0000\tminsplit = 3000.0000\tminbucket = 998.0000\tValue = 44218000.0000 \n",
            "elapsed = 136.07\tRound = 52\tcp = -0.9250167\tmaxdepth = 15.0000\tminsplit = 3000.0000\tminbucket = 999.0000\tValue = 44218000.0000 \n",
            "elapsed = 143.581\tRound = 53\tcp = -0.007770412\tmaxdepth = 15.0000\tminsplit = 2213.0000\tminbucket = 907.0000\tValue = 45303000.0000 \n",
            "elapsed = 41.457\tRound = 54\tcp = -0.4995181\tmaxdepth = 3.0000\tminsplit = 3000.0000\tminbucket = 751.0000\tValue = 44439000.0000 \n",
            "elapsed = 41.151\tRound = 55\tcp = -0.1819025\tmaxdepth = 3.0000\tminsplit = 3000.0000\tminbucket = 418.0000\tValue = 44198000.0000 \n",
            "elapsed = 145.402\tRound = 56\tcp = -0.02834147\tmaxdepth = 15.0000\tminsplit = 1302.0000\tminbucket = 1000.0000\tValue = 46149000.0000 \n",
            "elapsed = 41.879\tRound = 57\tcp = -0.2303328\tmaxdepth = 3.0000\tminsplit = 2.0000\tminbucket = 871.0000\tValue = 45781000.0000 \n",
            "elapsed = 198.642\tRound = 58\tcp = -0.3033247\tmaxdepth = 15.0000\tminsplit = 2.0000\tminbucket = 158.0000\tValue = 41525000.0000 \n",
            "elapsed = 57.438\tRound = 59\tcp = -0.344329\tmaxdepth = 4.0000\tminsplit = 3000.0000\tminbucket = 899.0000\tValue = 44223000.0000 \n",
            "elapsed = 157.47\tRound = 60\tcp = -0.435387\tmaxdepth = 14.0000\tminsplit = 1339.0000\tminbucket = 636.0000\tValue = 46013000.0000 \n",
            "elapsed = 42.469\tRound = 61\tcp = -0.2526469\tmaxdepth = 3.0000\tminsplit = 3000.0000\tminbucket = 277.0000\tValue = 44198000.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Timing stopped at: 47.44 0.611 49.82\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Pull BO history\n",
        "hist <- as.data.table(bayes_opt_result$History)\n",
        "\n",
        "# 2) Normalize columns present in history\n",
        "has_ratio <- \"minbucket_ratio\" %in% names(hist)\n",
        "\n",
        "# Cast integer-like params\n",
        "int_cols <- intersect(c(\"maxdepth\",\"minsplit\",\"minbucket\"), names(hist))\n",
        "if (length(int_cols)) hist[, (int_cols) := lapply(.SD, as.integer), .SDcols = int_cols]\n",
        "\n",
        "# Optional: derive minbucket from ratio if BO used minbucket_ratio\n",
        "if (has_ratio && !(\"minbucket\" %in% names(hist))) {\n",
        "  # Clamp to [1, floor(minsplit/2)]\n",
        "  hist[, minbucket := pmax(1L, as.integer(round(minsplit * minbucket_ratio)))]\n",
        "  hist[, minbucket := pmin(minbucket, as.integer(floor(minsplit / 2L)))]\n",
        "}\n",
        "\n",
        "# 3) For grouping, round cp a bit to merge near-duplicates produced by GP jitter\n",
        "hist[, cp_round := round(cp, 6)]\n",
        "\n",
        "# 4) Aggregate by unique combo -> mean and best observed Value\n",
        "group_cols <- intersect(c(\"cp_round\",\"maxdepth\",\"minsplit\",\"minbucket\"), names(hist))\n",
        "stopifnot(all(c(\"Value\", group_cols) %in% names(hist)))\n",
        "\n",
        "agg <- hist[, .(\n",
        "  mean_ganancia = mean(Value, na.rm = TRUE),\n",
        "  best_ganancia = max(Value, na.rm = TRUE),\n",
        "  n_evals       = .N\n",
        "), by = group_cols]\n",
        "\n",
        "# 5) Recover original cp (unrounded) by taking the average of cp per group (optional)\n",
        "if (\"cp\" %in% names(hist)) {\n",
        "  cp_map <- hist[, .(cp = mean(cp, na.rm = TRUE)), by = .(cp_round)]\n",
        "  agg <- cp_map[agg, on = \"cp_round\"]\n",
        "  setcolorder(agg, c(\"cp\",\"maxdepth\",\"minsplit\",\"minbucket\",\"mean_ganancia\",\"best_ganancia\",\"n_evals\",\"cp_round\"))\n",
        "  agg[, cp_round := NULL]\n",
        "} else {\n",
        "  setnames(agg, \"cp_round\", \"cp\")\n",
        "}\n",
        "\n",
        "# 6) Order and take top 100\n",
        "setorder(agg, -mean_ganancia, -best_ganancia, n_evals)\n",
        "top100 <- head(agg, 100)\n",
        "\n",
        "# 7) Show and (optionally) write to disk\n",
        "print(top100, nrows = 100)\n",
        "data.table::fwrite(top100, \"bo_top100_params.tsv\", sep = \"\\t\")\n"
      ],
      "metadata": {
        "id": "ZXHdvylhmKQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}